"""
æ‹¼éŸ³è§„èŒƒåŒ–å’Œå¤„ç†å·¥å…·æ¨¡å—ã€‚

åŠŸèƒ½ï¼š
- æ‹¼éŸ³æ ‡å‡†åŒ–ï¼ˆtone mark -> æ•°å­—å½¢å¼ | tone number -> æ ‡å‡†å½¢å¼ï¼‰
- éŸ³è°ƒæå–å’Œæ‹¼éŸ³åˆ†ç¦»
- æ‹¼éŸ³éªŒè¯å’Œæ¸…ç†
- å¤šéŸ³å­—è¯†åˆ«ï¼ˆå¦‚æœç›¸åŒæ±‰å­—æœ‰å¤šä¸ªæ‹¼éŸ³ï¼‰
"""
import re
from typing import List, Tuple, Optional, Dict, Set
from collections import defaultdict

# ğŸš€ ä¼˜åŒ–ï¼šé¢„ç¼–è¯‘å¸¸ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼ˆé¿å…æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°ç¼–è¯‘ï¼‰
# æ³¨æ„ï¼šå…è®¸0è¡¨ç¤ºè½»å£°ï¼Œ1-4è¡¨ç¤ºå£°è°ƒ
_TONE_MARK_PATTERN = re.compile(r'^[a-z]+[0-4]?$')
_PINYIN_BASE_PATTERN = re.compile(r'^([a-z\d]*?)(\d?)$')

# å£°è°ƒæ ‡è®°ç¬¦å·åˆ°æ•°å­—çš„æ˜ å°„ï¼ˆç”¨äº tone mark è½¬ tone numberï¼‰
# æ˜ å°„æ ¼å¼ï¼šæ ‡è®°å­—ç¬¦ -> (å­—æ¯, éŸ³è°ƒå·)
TONE_MARK_TO_NUM = {
    'Ä': ('a', '1'), 'Ã¡': ('a', '2'), 'Ç': ('a', '3'), 'Ã ': ('a', '4'),
    'Ä“': ('e', '1'), 'Ã©': ('e', '2'), 'Ä›': ('e', '3'), 'Ã¨': ('e', '4'),
    'Ä«': ('i', '1'), 'Ã­': ('i', '2'), 'Ç': ('i', '3'), 'Ã¬': ('i', '4'),
    'Å': ('o', '1'), 'Ã³': ('o', '2'), 'Ç’': ('o', '3'), 'Ã²': ('o', '4'),
    'Å«': ('u', '1'), 'Ãº': ('u', '2'), 'Ç”': ('u', '3'), 'Ã¹': ('u', '4'),
    'Ç–': ('v', '1'), 'Ç˜': ('v', '2'), 'Çš': ('v', '3'), 'Çœ': ('v', '4'),
    'Å„': ('n', '2'), 'Åˆ': ('n', '3'), 'Ç¹': ('n', '4'),
    'á¸¿': ('m', '2'),
}

# å¸¸è§æ±‰å­—çš„å¤šéŸ³å­—æ˜ å°„ï¼ˆå¯æ‰©å±•ï¼‰
# ğŸ”´ æ”¹è¿›ï¼šæ›´å®Œæ•´çš„å¤šéŸ³å­—æ˜ å°„ï¼Œæ¶µç›–å¸¸è§æ±‰å­—
COMMON_POLYPHONIC_CHARS = {
    # å­¦æœ¯/æ–‡è¨€
    'ä¸­': ['zhong1', 'zhong4'],          # ä¸­å›½ vs ä¸­é—´
    'é•¿': ['chang2', 'zhang3'],          # é•¿åº¦ vs é•¿å¤§
    'è¿˜': ['hai2', 'huan2'],             # è¿˜è¦ vs è¿˜åŸ
    'è¡Œ': ['xing2', 'hang2'],            # è¡Œèµ° vs è¡Œä¸š
    'åº¦': ['du4', 'duo2'],               # æ¸©åº¦ vs åº¦è¿‡
    'é‡': ['zhong4', 'chong2'],          # é‡é‡ vs é‡è§†
    'ä¸º': ['wei2', 'wei4'],              # å› ä¸º vs ä¸ºäº†
    'ç€': ['zhe5', 'zhao2', 'zhu2'],     # ç€(è½»å£°) vs ç€ç« vs ç€æ€¥
    'äº†': ['le5', 'liao3'],              # äº†(è½»å£°) vs äº†è§£
    
    # å¸¸è§å­—
    'å¥½': ['hao3', 'hao4'],              # å¥½çš„ vs å¥½çœ‹
    'å¤š': ['duo1', 'duo2'],              # å¤šå°‘ vs å¤šæ„å–„æ„Ÿ
    'å¤„': ['chu3', 'chu4'],              # å¤„ç† vs åˆ°å¤„
    'å·®': ['cha1', 'cha4', 'ci1'],       # å·®ä¸å¤š vs å·®è· vs å‚å·®
    'ä¾¿': ['bian4', 'pian2'],            # ä¾¿å®œ vs ä¾¿åˆ©
    'èƒŒ': ['bei3', 'bei4'],              # èƒŒåŒ… vs èƒŒè¯—
    'è¢«': ['bei4', 'bei3'],              # è¢«å­ vs è¢«æ‰“
    'å¼¹': ['tan2', 'dan4'],              # å¼¹ç´ vs å¼¹ç°§
    'è½¬': ['zhuan3', 'zhuan4'],          # è½¬èº« vs è½¬å‘
    'æ™•': ['yun1', 'yun4'],              # æ™•è½¦ vs å‘æ™•
    
    # æ—¶é—´/æ•°å­—
    'ä¸€': ['yi1'],                       # è™½ç„¶æœ‰å¤šç§ç”¨æ³•ï¼Œä½†ä¸»è¦å‘éŸ³ä¸º yi1
    'æ•°': ['shu3', 'shuo4'],             # æ•°å­— vs æ•°è½
    'é—´': ['jian1', 'jian3'],            # æ—¶é—´ vs é—´éš”
    'æœˆ': ['yue4'],                      # æœˆä»½
    
    # å£è¯­/åŠ©è¯
    'å—': ['ma5'],                       # å—(è½»å£°ç–‘é—®è¯)
    'å‘¢': ['ne5'],                       # å‘¢(è½»å£°ç–‘é—®è¯)
    'çš„': ['de5', 'di4', 'di2'],         # çš„(è½»å£°åŠ©è¯) vs çš„ç¡® vs ç›®çš„åœ°
    'å¾—': ['de5', 'dei3'],               # å¾—(è½»å£°) vs å¾—åˆ°
    'åœ°': ['de5', 'di4'],                # åœ°(è½»å£°) vs åœ°çƒ
    'å§': ['ba5'],                       # å§(è½»å£°è¯­æ°”è¯)
    'å‘€': ['ya5', 'a5'],                 # å‘€(è½»å£°) vs å•Š
    'å–”': ['o5', 'wo3'],                 # å–”(è½»å£°)
    
    # å…¶ä»–å¸¸è§å¤šéŸ³å­—
    'éƒ½': ['du1', 'dou1'],               # éƒ½å¸‚ vs éƒ½(çš†)
    'è¿‡': ['guo4', 'guo5'],              # è¿‡å» vs è¿‡(è½»å£°)
    'å¼€': ['kai1'],                      # æ‰“å¼€
    'å¯¹': ['dui4'],                      # å¯¹çš„
    'è¿˜': ['hai2', 'huan2'],             # è¿˜è¦ vs è¿˜åŸ
    'ç»™': ['gei3', 'ji3'],               # ç»™æˆ‘ vs ä¾›ç»™
    'çœ‹': ['kan4', 'kan1'],              # çœ‹ä¹¦ vs çœ‹å®ˆ
    'æ¥': ['lai2'],                      # æ¥è‡ª
    'ä¸Š': ['shang4', 'shang3'],          # ä¸Šé¢ vs ä¸Šå‡
    'è¯´': ['shuo1'],                     # è¯´è¯
    'è¦': ['yao4', 'yao1'],              # è¦æ±‚ vs è¦æ­»äº†
    'ç§': ['zhong3', 'zhong4'],          # ç§å­ vs ç§æ¤
    'ä½œ': ['zuo4', 'zuo1'],              # ä½œç”¨ vs ä½œåŠ
    'èƒ½': ['neng2', 'nai4'],             # èƒ½åŠ› vs èƒ½è€
    'ä¼š': ['hui4', 'hui3'],              # ä¼šè®® vs ä¼šåˆ
    'å‘': ['fa1', 'fa3'],                # å‘ç”Ÿ vs å‘ç°
    'å’Œ': ['he2', 'he4', 'huo2'],        # å’Œå¹³ vs å’Œè° vs å’Œé¢
    'æˆ–': ['huo4'],                      # æˆ–è€…
    'é€š': ['tong1'],                     # é€šé“
    'ç”¨': ['yong4'],                     # ä½¿ç”¨
}

# ğŸ”´ æ”¹è¿›ï¼šè½»å£°æ‹¼éŸ³æ˜ å°„è¡¨ - æ”¹ä¸ºç”¨ 0 è¡¨ç¤ºè½»å£°
# è¿™äº›æ‹¼éŸ³åœ¨æ±‰è¯­ä¸­é€šå¸¸æ²¡æœ‰æ ‡æ³¨å£°è°ƒï¼Œè¡¨ç¤ºè½»å£°ï¼ˆç¬¬5å£°ï¼‰
# ç°åœ¨ç»Ÿä¸€ç”¨ "0" è¡¨ç¤ºè½»å£°ï¼Œæ›´ç›´è§‚ä¸”é¿å…ä¸ 1-4 å£°æ··æ·†
LIGHT_TONE_PINYINS = {
    'de': 'de0',      # çš„ã€å¾—ã€åœ°ï¼ˆè½»å£°ï¼‰
    'le': 'le0',      # äº†ï¼ˆè½»å£°ï¼‰
    'men': 'men0',    # ä»¬ï¼ˆå¤æ•°æ ‡è®°ï¼Œè½»å£°ï¼‰
    'zhe': 'zhe0',    # ç€ï¼ˆè½»å£°ï¼‰
    'zi': 'zi0',      # å­ï¼ˆåç¼€ï¼Œè½»å£°ï¼‰
    'me': 'me0',      # å—ï¼ˆç–‘é—®è¯­æ°”ï¼Œè½»å£°ï¼‰
    'ba': 'ba0',      # å§ï¼ˆè¯­æ°”è¯ï¼Œè½»å£°ï¼‰
    'ma': 'ma0',      # å—ï¼ˆç–‘é—®è¯­æ°”ï¼Œè½»å£°ï¼‰
    'ne': 'ne0',      # å‘¢ï¼ˆç–‘é—®è¯­æ°”ï¼Œè½»å£°ï¼‰
    'a': 'a0',        # å•Šï¼ˆæ„Ÿå¹è¯ï¼Œè½»å£°ï¼‰
    'o': 'o0',        # å–”ï¼ˆæ„Ÿå¹è¯ï¼Œè½»å£°ï¼‰
    'er': 'er0',      # å„¿/è€³ï¼ˆåœ¨è¯å°¾æ—¶ä¸ºè½»å£°ï¼‰
}

# ğŸš€ ä¼˜åŒ–ï¼šç¼“å­˜è½»å£°æ‹¼éŸ³çš„keysé›†åˆï¼ˆç”¨äºå¿«é€Ÿlookupï¼‰
_LIGHT_TONE_PINYINS_KEYS = frozenset(LIGHT_TONE_PINYINS.keys())


def tone_mark_to_number(pinyin_with_mark: str) -> str:
    """
    å°†å¸¦å£°è°ƒæ ‡è®°çš„æ‹¼éŸ³è½¬æ¢ä¸ºæ•°å­—éŸ³è°ƒå½¢å¼ã€‚
    
    ä¾‹ï¼š
        'mÄ' -> 'ma1'
        'hÇo' -> 'hao3'
    
    Args:
        pinyin_with_mark: å¸¦å£°è°ƒæ ‡è®°çš„æ‹¼éŸ³ï¼ˆå¦‚ 'mÄ'ï¼‰
    
    Returns:
        æ•°å­—éŸ³è°ƒå½¢å¼çš„æ‹¼éŸ³ï¼ˆå¦‚ 'ma1'ï¼‰
        å¦‚æœæ— æ³•è½¬æ¢ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
    """
    # ğŸš€ ä¼˜åŒ–ï¼šå¿«è·¯å¾„æ£€æŸ¥ï¼ˆå¤§å¤šæ•°æ‹¼éŸ³ä¸åŒ…å«å£°è°ƒæ ‡è®°ï¼‰
    if not pinyin_with_mark or all(c not in TONE_MARK_TO_NUM for c in pinyin_with_mark):
        return pinyin_with_mark
    
    result = []
    tone = ''
    for char in pinyin_with_mark:
        if char in TONE_MARK_TO_NUM:
            letter, tone_num = TONE_MARK_TO_NUM[char]
            result.append(letter)
            tone = tone_num
        else:
            result.append(char)
    
    # å°†éŸ³è°ƒé™„åŠ åˆ°æœ€å
    return ''.join(result) + tone


def normalize_pinyin(pinyin: str) -> str:
    """
    è§„èŒƒåŒ–å•ä¸ªæ‹¼éŸ³ã€‚
    
    - å»é™¤é¦–å°¾ç©ºæ ¼
    - è½¬ä¸ºå°å†™
    - å°† tone mark è½¬ä¸º tone numberï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    - å¤„ç† Ã¼ -> v çš„å…¼å®¹å½¢å¼
    
    Args:
        pinyin: åŸå§‹æ‹¼éŸ³å­—ç¬¦ä¸²
    
    Returns:
        è§„èŒƒåŒ–åçš„æ‹¼éŸ³
    
    Raises:
        ValueError: å¦‚æœè¾“å…¥ä¸ºç©ºæˆ–æ— æ•ˆ
    """
    if not pinyin or not pinyin.strip():
        raise ValueError("æ‹¼éŸ³ä¸èƒ½ä¸ºç©º")
    
    pinyin = pinyin.strip().lower()
    
    # è½¬æ¢ tone mark åˆ° tone number
    pinyin = tone_mark_to_number(pinyin)
    
    # å¤„ç† Ã¼ çš„å¤šç§è¡¨ç¤ºæ³•ï¼šÃ¼, u:, v
    pinyin = pinyin.replace('Ã¼', 'v').replace('u:', 'v')
    
    return pinyin


def normalize_light_tone(pinyin: str) -> str:
    """
    ğŸ”´ æ”¹è¿›ï¼šè§„èŒƒåŒ–è½»å£°æ‹¼éŸ³ä¸ºå¸¦"0"çš„å½¢å¼ã€‚
    
    æŸäº›æ‹¼éŸ³åœ¨æ ‡å‡†æ³¨éŸ³ä¸­ä¸å¸¦å£°è°ƒæ•°å­—ï¼Œä½†å®é™…ä¸Šæ˜¯è½»å£°ã€‚
    æœ¬å‡½æ•°å°†è¿™äº›è½»å£°æ‹¼éŸ³è½¬æ¢ä¸ºå¸¦"0"çš„æ ‡å‡†æ ¼å¼ã€‚
    
    ä½¿ç”¨ "0" çš„ä¼˜åŠ¿ï¼š
    - 0 è¡¨ç¤º"æ— å£°è°ƒ" = "è½»å£°"ï¼Œç¬¦åˆç›´è§‰
    - é¿å…ä¸ 1-4 å£°æ··æ·†
    - æ¨¡å‹å­¦ä¹ æ›´æ¸…æ™°
    - ç¼–ç æ›´ç®€æ´
    
    ä¾‹ï¼š
        'le' -> 'le0'     ï¼ˆäº†ï¼‰
        'de' -> 'de0'     ï¼ˆçš„ï¼‰
        'men' -> 'men0'   ï¼ˆä»¬ï¼‰
        'ma1' -> 'ma1'    ï¼ˆä¸å¤„ç†å·²æœ‰å£°è°ƒçš„ï¼‰
    
    Args:
        pinyin: è§„èŒƒåŒ–åçš„æ‹¼éŸ³å­—ç¬¦ä¸²
    
    Returns:
        è½¬æ¢åçš„æ‹¼éŸ³ï¼ˆå¸¦è½»å£°æ ‡è®°"0"ï¼‰
    
    è¯´æ˜ï¼š
        è¿™æ˜¯é‡è¦çš„ä¿®å¤ï¼Œå› ä¸ºæ•°æ®ä¸­ 28.1% çš„æ ·æœ¬åŒ…å«è½»å£°æ‹¼éŸ³ï¼Œ
        å¦‚æœä¸å¤„ç†è¿™äº›æ‹¼éŸ³ï¼Œæ¨¡å‹åœ¨æ¨ç†æ—¶ä¼šå°†å…¶è¯†åˆ«ä¸º <unk>ï¼ˆæœªçŸ¥è¯ï¼‰ã€‚
    """
    # ğŸš€ ä¼˜åŒ–ï¼šå¿«è·¯å¾„æ£€æŸ¥ï¼ˆé¿å…ä¸å¿…è¦çš„å­—ç¬¦éå†ï¼‰
    if pinyin and pinyin[-1].isdigit():
        return pinyin  # å·²ç»æœ‰å£°è°ƒï¼Œå¿«é€Ÿè¿”å›
    
    # ä½¿ç”¨ç¼“å­˜çš„keysé›†åˆè¿›è¡Œå¿«é€Ÿlookupï¼ˆO(1)ï¼‰
    pinyin_lower = pinyin.lower()
    if pinyin_lower in _LIGHT_TONE_PINYINS_KEYS:
        return LIGHT_TONE_PINYINS[pinyin_lower]
    
    return pinyin


def extract_tone(pinyin: str) -> Tuple[str, Optional[str]]:
    """
    ä»æ‹¼éŸ³ä¸­æå–éŸ³è°ƒã€‚
    
    Args:
        pinyin: æ ‡å‡†åŒ–çš„æ‹¼éŸ³ï¼ˆå¦‚ 'ma1'ï¼‰
    
    Returns:
        (æ‹¼éŸ³ä¸å«éŸ³è°ƒéƒ¨åˆ†, éŸ³è°ƒå·)ï¼Œä¾‹å¦‚ ('ma', '1')
        å¦‚æœæ²¡æœ‰éŸ³è°ƒåˆ™è¿”å› (æ‹¼éŸ³, None)
    """
    # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
    match = _PINYIN_BASE_PATTERN.match(pinyin)
    if match:
        base, tone = match.groups()
        return base, tone if tone else None
    return pinyin, None


def normalize_pinyin_sequence(pinyin_str: str, separator: str = ' ') -> str:
    """
    è§„èŒƒåŒ–æ‹¼éŸ³åºåˆ—ã€‚
    
    ğŸ”´ æ›´æ–°ï¼šç°åœ¨åŒ…æ‹¬è½»å£°æ‹¼éŸ³çš„è§„èŒƒåŒ–å¤„ç†
    
    Args:
        pinyin_str: æ‹¼éŸ³åºåˆ—å­—ç¬¦ä¸²ï¼ˆç”¨åˆ†éš”ç¬¦åˆ†å¼€çš„å¤šä¸ªæ‹¼éŸ³ï¼‰
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦ï¼Œé»˜è®¤ä¸ºç©ºæ ¼
    
    Returns:
        è§„èŒƒåŒ–åçš„æ‹¼éŸ³åºåˆ—ï¼ˆåŒæ ·ç”¨åˆ†éš”ç¬¦åˆ†å¼€ï¼‰
    """
    pinyins = pinyin_str.split(separator)
    normalized = []
    for p in pinyins:
        if p.strip():
            p = normalize_pinyin(p)          # å…ˆè§„èŒƒåŒ–
            p = normalize_light_tone(p)      # å†å¤„ç†è½»å£°
            normalized.append(p)
    return separator.join(normalized)


def validate_pinyin(pinyin: str) -> bool:
    """
    éªŒè¯æ‹¼éŸ³æ˜¯å¦æœ‰æ•ˆã€‚
    
    æœ‰æ•ˆæ‹¼éŸ³åº”è¯¥ï¼š
    - ä¸ä¸ºç©º
    - åŒ…å«è‡³å°‘ä¸€ä¸ªå­—æ¯
    - å¯èƒ½åŒ…å«æ•°å­—éŸ³è°ƒï¼ˆ0-4ï¼‰ï¼Œå…¶ä¸­ 0 è¡¨ç¤ºè½»å£°
    - ä¸åº”è¯¥åŒ…å«å…¶ä»–ç‰¹æ®Šå­—ç¬¦
    
    Args:
        pinyin: è§„èŒƒåŒ–åçš„æ‹¼éŸ³
    
    Returns:
        æ˜¯å¦ä¸ºæœ‰æ•ˆæ‹¼éŸ³
    """
    # ğŸš€ ä¼˜åŒ–ï¼šå¿«è·¯å¾„æ£€æŸ¥
    if not pinyin or not pinyin.strip():
        return False
    
    # ä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå…è®¸ï¼ša-z, v (ä»£è¡¨Ã¼), æ•°å­— 0-4ï¼ˆ0=è½»å£°, 1-4=å£°è°ƒï¼‰ï¼‰
    return _TONE_MARK_PATTERN.match(pinyin) is not None


def validate_pinyin_sequence(pinyin_str: str, separator: str = ' ') -> bool:
    """
    éªŒè¯æ‹¼éŸ³åºåˆ—æ˜¯å¦æœ‰æ•ˆã€‚
    
    Args:
        pinyin_str: æ‹¼éŸ³åºåˆ—
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦
    
    Returns:
        åºåˆ—ä¸­æ‰€æœ‰æ‹¼éŸ³æ˜¯å¦éƒ½æœ‰æ•ˆï¼ˆç©ºåºåˆ—è¿”å› Falseï¼‰
    """
    if not pinyin_str or not pinyin_str.strip():
        return False
    
    pinyins = pinyin_str.split(separator)
    valid_pinyins = [p.strip() for p in pinyins if p.strip()]
    
    if not valid_pinyins:
        return False
    
    return all(validate_pinyin(p) for p in valid_pinyins)


def split_pinyin_sequence(pinyin_str: str, separator: str = ' ') -> List[str]:
    """
    æ‹†åˆ†æ‹¼éŸ³åºåˆ—ä¸ºå•ä¸ªæ‹¼éŸ³åˆ—è¡¨ã€‚
    
    Args:
        pinyin_str: æ‹¼éŸ³åºåˆ—
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦
    
    Returns:
        æ‹¼éŸ³åˆ—è¡¨
    
    Raises:
        ValueError: å¦‚æœè¾“å…¥ä¸ºç©ºæˆ–æ— æ•ˆ
    """
    if not pinyin_str or not pinyin_str.strip():
        raise ValueError("æ‹¼éŸ³åºåˆ—ä¸èƒ½ä¸ºç©º")
    
    return [p.strip() for p in pinyin_str.split(separator) if p.strip()]


def join_pinyin_sequence(pinyins: List[str], separator: str = ' ') -> str:
    """
    å°†æ‹¼éŸ³åˆ—è¡¨åˆå¹¶ä¸ºåºåˆ—å­—ç¬¦ä¸²ã€‚
    
    Args:
        pinyins: æ‹¼éŸ³åˆ—è¡¨
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦
    
    Returns:
        æ‹¼éŸ³åºåˆ—å­—ç¬¦ä¸²
    
    Raises:
        ValueError: å¦‚æœè¾“å…¥åˆ—è¡¨ä¸ºç©º
    """
    if not pinyins:
        raise ValueError("æ‹¼éŸ³åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    return separator.join(pinyins)


def is_polyphonic_char(hanzi: str) -> bool:
    """
    åˆ¤æ–­æ±‰å­—æ˜¯å¦ä¸ºå¸¸è§å¤šéŸ³å­—ã€‚
    
    Args:
        hanzi: å•ä¸ªæ±‰å­—
    
    Returns:
        æ˜¯å¦ä¸ºå¤šéŸ³å­—
    
    Raises:
        ValueError: å¦‚æœè¾“å…¥ä¸æ˜¯å•ä¸ªæ±‰å­—
    """
    if not hanzi or len(hanzi) != 1:
        raise ValueError("è¾“å…¥å¿…é¡»æ˜¯å•ä¸ªæ±‰å­—")
    
    return hanzi in COMMON_POLYPHONIC_CHARS


def get_possible_pinyins(hanzi: str) -> Optional[List[str]]:
    """
    è·å–å¤šéŸ³å­—çš„å¯èƒ½æ‹¼éŸ³åˆ—è¡¨ã€‚
    
    Args:
        hanzi: å•ä¸ªæ±‰å­—
    
    Returns:
        æ‹¼éŸ³åˆ—è¡¨ï¼Œå¦‚æœä¸æ˜¯å¤šéŸ³å­—è¿”å› None
    """
    return COMMON_POLYPHONIC_CHARS.get(hanzi)


def disambiguate_polyphonic(
    hanzi_str: str, 
    pinyin_str: str, 
    context_window: int = 2,
    separator: str = ' '
) -> str:
    """
    ğŸ”´ æ–°å¢ï¼šå¤šéŸ³å­—æ¶ˆæ­§å‡½æ•°ã€‚
    
    å°è¯•æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­å¤šéŸ³å­—çš„æ­£ç¡®è¯»éŸ³ã€‚
    è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å¯å‘å¼å®ç°ï¼Œå¯ä»¥ä½œä¸ºæœªæ¥æ”¹è¿›çš„åŸºç¡€ã€‚
    
    è¯´æ˜ï¼š
        ç”±äºå½“å‰æ•°æ®ä¸­å·²ç»åŒ…å«äº†æ­£ç¡®çš„æ‹¼éŸ³æ ‡æ³¨ï¼Œ
        è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºï¼š
        1. éªŒè¯æ•°æ®ä¸€è‡´æ€§
        2. æ£€æµ‹æ½œåœ¨çš„å¤šéŸ³å­—æ ‡æ³¨é”™è¯¯
        3. ä¸ºæœªæ¥çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨¡å‹æä¾›åŸºç¡€
    
    Args:
        hanzi_str: æ±‰å­—å­—ç¬¦ä¸²
        pinyin_str: æ‹¼éŸ³åºåˆ—ï¼ˆå¸¦å£°è°ƒï¼‰
        context_window: ä¸Šä¸‹æ–‡çª—å£å¤§å°
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦
    
    Returns:
        æ¶ˆæ­§åçš„æ‹¼éŸ³åºåˆ—
    
    ä¾‹ï¼š
        è¾“å…¥ï¼šhanzi_str="ä¸­å›½", pinyin_str="zhong4 guo2"
        è¾“å‡ºï¼š"zhong1 guo2"ï¼ˆå¦‚æœæ ¹æ®è¯å…¸è§„åˆ™ï¼‰
    """
    pinyins = split_pinyin_sequence(pinyin_str, separator)
    hanzis = list(hanzi_str)
    
    if len(hanzis) != len(pinyins):
        # é•¿åº¦ä¸åŒ¹é…ï¼Œè¿”å›åŸæ ·
        return pinyin_str
    
    result = []
    for i, (hanzi, pinyin) in enumerate(zip(hanzis, pinyins)):
        # å¦‚æœæ˜¯å¤šéŸ³å­—ï¼Œå¯ä»¥è€ƒè™‘ä¸Šä¸‹æ–‡
        if is_polyphonic_char(hanzi):
            possible = get_possible_pinyins(hanzi)
            if possible and pinyin in possible:
                # æ ‡æ³¨çš„æ‹¼éŸ³åœ¨å¯èƒ½åˆ—è¡¨ä¸­ï¼Œä¿æŒåŸæ ·
                result.append(pinyin)
            elif possible:
                # æ ‡æ³¨çš„æ‹¼éŸ³ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œè¿™å¯èƒ½æ˜¯æ•°æ®é”™è¯¯
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯èƒ½çš„æ‹¼éŸ³ä½œä¸ºé»˜è®¤
                result.append(possible[0])
            else:
                result.append(pinyin)
        else:
            result.append(pinyin)
    
    return separator.join(result)


def get_polyphonic_statistics(
    hanzi_str: str, 
    pinyin_str: str, 
    separator: str = ' '
) -> Dict[str, dict]:
    """
    ğŸ”´ æ–°å¢ï¼šè·å–å¤šéŸ³å­—ç»Ÿè®¡ä¿¡æ¯ã€‚
    
    åˆ†æå­—ç¬¦ä¸²ä¸­å¤šéŸ³å­—çš„åˆ†å¸ƒæƒ…å†µã€‚
    
    Args:
        hanzi_str: æ±‰å­—å­—ç¬¦ä¸²
        pinyin_str: æ‹¼éŸ³åºåˆ—
        separator: æ‹¼éŸ³åˆ†éš”ç¬¦
    
    Returns:
        å¤šéŸ³å­—ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        æ ¼å¼: {hanzi: {pinyins: [...], count: N, position: [...]}}
    
    ä¾‹ï¼š
        è¾“å…¥ï¼šhanzi_str="ä¸­å›½ä¸­å¿ƒ", pinyin_str="zhong1 guo2 zhong1 xin1"
        è¾“å‡ºï¼š{
            'ä¸­': {'pinyins': ['zhong1'], 'count': 2, 'positions': [0, 2]}
        }
    """
    pinyins = split_pinyin_sequence(pinyin_str, separator)
    hanzis = list(hanzi_str)
    
    stats = {}
    for i, (hanzi, pinyin) in enumerate(zip(hanzis, pinyins)):
        if is_polyphonic_char(hanzi):
            if hanzi not in stats:
                stats[hanzi] = {
                    'pinyins': set(),
                    'count': 0,
                    'positions': []
                }
            stats[hanzi]['pinyins'].add(pinyin)
            stats[hanzi]['count'] += 1
            stats[hanzi]['positions'].append(i)
    
    # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨
    for hanzi in stats:
        stats[hanzi]['pinyins'] = sorted(list(stats[hanzi]['pinyins']))
    
    return stats


class PinyinStatistics:
    """
    ğŸš€ æ”¹è¿›ï¼šç»Ÿè®¡æ‹¼éŸ³å’Œæ±‰å­—çš„åˆ†å¸ƒæƒ…å†µï¼ˆæ·»åŠ ç¼“å­˜å’Œæ‰¹é‡å¤„ç†ï¼‰ã€‚
    """
    
    def __init__(self):
        self.pinyin_freq = defaultdict(int)
        self.hanzi_freq = defaultdict(int)
        self.pinyin_hanzi_pairs = defaultdict(set)  # pinyin -> set of hanzi
        self.hanzi_pinyins = defaultdict(set)  # hanzi -> set of pinyin
        self.total_pairs = 0
        # ç¼“å­˜ï¼šå»¶è¿Ÿè®¡ç®—çš„ç»“æœ
        self._polyphonic_cache = None
        self._homophonic_cache = None
    
    def update_from_data(self, hanzi_str: str, pinyin_str: str, separator: str = ' '):
        """
        ä»æ•°æ®å¯¹æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ã€‚
        
        Args:
            hanzi_str: æ±‰å­—å­—ç¬¦ä¸²
            pinyin_str: æ‹¼éŸ³åºåˆ—
            separator: æ‹¼éŸ³åˆ†éš”ç¬¦
        
        Raises:
            ValueError: å¦‚æœæ±‰å­—å’Œæ‹¼éŸ³æ•°é‡ä¸åŒ¹é…
        """
        try:
            pinyins = split_pinyin_sequence(pinyin_str, separator)
        except ValueError:
            # å¤„ç†ç©ºåºåˆ—
            return
        
        hanzis = list(hanzi_str)
        
        if len(hanzis) != len(pinyins):
            raise ValueError(f"æ±‰å­—æ•°é‡({len(hanzis)})ä¸æ‹¼éŸ³æ•°é‡({len(pinyins)})ä¸åŒ¹é…: {hanzi_str} vs {pinyin_str}")
        
        # æŒ‰å­—ç¬¦é€ä¸€å…³è”
        for hanzi, pinyin in zip(hanzis, pinyins):
            self.pinyin_freq[pinyin] += 1
            self.hanzi_freq[hanzi] += 1
            self.pinyin_hanzi_pairs[pinyin].add(hanzi)
            self.hanzi_pinyins[hanzi].add(pinyin)
            self.total_pairs += 1
        
        # æ¸…é™¤ç¼“å­˜ï¼ˆæ•°æ®å·²æ›´æ–°ï¼‰
        self._polyphonic_cache = None
        self._homophonic_cache = None
    
    def update_from_batch(self, data: List[Tuple[str, str]]):
        """
        ğŸš€ æ–°å¢ï¼šæ‰¹é‡æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰ã€‚
        
        Args:
            data: [(hanzi_str, pinyin_str), ...] åˆ—è¡¨
        """
        for hanzi_str, pinyin_str in data:
            try:
                self.update_from_data(hanzi_str, pinyin_str)
            except ValueError:
                # è·³è¿‡æ— æ•ˆæ•°æ®
                continue
    
    def get_pinyin_frequency(self, pinyin: str) -> int:
        """è·å–æ‹¼éŸ³å‡ºç°é¢‘ç‡ã€‚"""
        return self.pinyin_freq.get(pinyin, 0)
    
    def get_hanzi_frequency(self, hanzi: str) -> int:
        """è·å–æ±‰å­—å‡ºç°é¢‘ç‡ã€‚"""
        return self.hanzi_freq.get(hanzi, 0)
    
    def get_polyphonic_hanzis(self) -> Dict[str, set]:
        """
        è·å–æœ‰å¤šä¸ªæ‹¼éŸ³çš„æ±‰å­—ï¼ˆå¤šéŸ³å­—ï¼‰ã€‚
        
        ğŸš€ ä¼˜åŒ–ï¼šç»“æœç¼“å­˜ï¼ˆå»¶è¿Ÿè®¡ç®—ï¼‰
        """
        if self._polyphonic_cache is None:
            self._polyphonic_cache = {
                h: p for h, p in self.hanzi_pinyins.items() if len(p) > 1
            }
        return self._polyphonic_cache
    
    def get_homophonic_hanzis(self) -> Dict[str, set]:
        """
        è·å–å¤šä¸ªæ±‰å­—å…±äº«åŒä¸€ä¸ªæ‹¼éŸ³çš„æƒ…å†µï¼ˆåŒéŸ³å­—ï¼‰ã€‚
        
        ğŸš€ ä¼˜åŒ–ï¼šç»“æœç¼“å­˜ï¼ˆå»¶è¿Ÿè®¡ç®—ï¼‰
        """
        if self._homophonic_cache is None:
            self._homophonic_cache = {
                p: h for p, h in self.pinyin_hanzi_pairs.items() if len(h) > 1
            }
        return self._homophonic_cache
    
    def get_top_pinyins(self, n: int = 20) -> List[Tuple[str, int]]:
        """
        ğŸš€ æ–°å¢ï¼šè·å–é¢‘ç‡æœ€é«˜çš„æ‹¼éŸ³ã€‚
        
        Args:
            n: è¿”å›å‰nä¸ª
        
        Returns:
            [(æ‹¼éŸ³, é¢‘ç‡), ...] æŒ‰é¢‘ç‡é™åºæ’åˆ—
        """
        return sorted(self.pinyin_freq.items(), key=lambda x: x[1], reverse=True)[:n]
    
    def get_top_hanzis(self, n: int = 20) -> List[Tuple[str, int]]:
        """
        ğŸš€ æ–°å¢ï¼šè·å–é¢‘ç‡æœ€é«˜çš„æ±‰å­—ã€‚
        
        Args:
            n: è¿”å›å‰nä¸ª
        
        Returns:
            [(æ±‰å­—, é¢‘ç‡), ...] æŒ‰é¢‘ç‡é™åºæ’åˆ—
        """
        return sorted(self.hanzi_freq.items(), key=lambda x: x[1], reverse=True)[:n]
    
    def get_stats_summary(self) -> Dict[str, any]:
        """
        ğŸš€ æ–°å¢ï¼šè·å–ç»Ÿè®¡æ‘˜è¦å­—å…¸ï¼ˆä¾¿äºåºåˆ—åŒ–å’Œæ—¥å¿—ï¼‰ã€‚
        
        Returns:
            ç»Ÿè®¡æ‘˜è¦å­—å…¸
        """
        polyphonic = self.get_polyphonic_hanzis()
        homophonic = self.get_homophonic_hanzis()
        
        return {
            'total_pairs': self.total_pairs,
            'unique_pinyins': len(self.pinyin_freq),
            'unique_hanzis': len(self.hanzi_freq),
            'polyphonic_count': len(polyphonic),
            'homophonic_count': len(homophonic),
            'avg_pinyins_per_hanzi': self.total_pairs / len(self.hanzi_freq) if self.hanzi_freq else 0,
            'avg_hanzis_per_pinyin': self.total_pairs / len(self.pinyin_freq) if self.pinyin_freq else 0,
        }
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦ã€‚"""
        stats = self.get_stats_summary()
        print(f"æ€»æ‹¼éŸ³-æ±‰å­—å¯¹æ•°: {stats['total_pairs']}")
        print(f"å”¯ä¸€æ‹¼éŸ³æ•°: {stats['unique_pinyins']}")
        print(f"å”¯ä¸€æ±‰å­—æ•°: {stats['unique_hanzis']}")
        print(f"å¤šéŸ³å­—æ•°: {stats['polyphonic_count']}")
        print(f"åŒéŸ³å­—ç»„æ•°: {stats['homophonic_count']}")
        print(f"å¹³å‡æ¯ä¸ªæ±‰å­—å¯¹åº”{stats['avg_pinyins_per_hanzi']:.2f}ä¸ªæ‹¼éŸ³")
        print(f"å¹³å‡æ¯ä¸ªæ‹¼éŸ³å¯¹åº”{stats['avg_hanzis_per_pinyin']:.2f}ä¸ªæ±‰å­—")
        
        # æ‰“å°å¤šéŸ³å­—ç¤ºä¾‹
        polyphonic = self.get_polyphonic_hanzis()
        if polyphonic:
            print("\nå¤šéŸ³å­—ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
            for hanzi, pinyins in list(polyphonic.items())[:10]:
                print(f"  {hanzi}: {', '.join(sorted(pinyins))}")
        
        # æ‰“å°é¢‘ç‡æœ€é«˜çš„æ‹¼éŸ³
        print("\né¢‘ç‡æœ€é«˜çš„æ‹¼éŸ³ï¼ˆå‰10ä¸ªï¼‰:")
        for pinyin, freq in self.get_top_pinyins(10):
            print(f"  {pinyin}: {freq} æ¬¡")


if __name__ == '__main__':
    # æµ‹è¯•ç¤ºä¾‹
    print("=== æ‹¼éŸ³è§„èŒƒåŒ–æµ‹è¯• ===")
    test_cases = [
        'ma1',
        'hÇo',
        'BEIJING',
        'zhÅng',
        'le',  # è½»å£°æ‹¼éŸ³
        'de',
    ]
    for case in test_cases:
        try:
            normalized = normalize_pinyin(case)
            normalized = normalize_light_tone(normalized)
            print(f"{case:15s} -> {normalized}")
        except ValueError as e:
            print(f"{case:15s} -> ERROR: {e}")
    
    print("\n=== æ‹¼éŸ³æå–æµ‹è¯• ===")
    test_pinyins = ['ma1', 'hao', 'zhang3', 'le0']
    for p in test_pinyins:
        try:
            base, tone = extract_tone(p)
            print(f"{p:10s} -> base='{base}', tone='{tone}'")
        except Exception as e:
            print(f"{p:10s} -> ERROR: {e}")
    
    print("\n=== æ‹¼éŸ³éªŒè¯æµ‹è¯• ===")
    test_validations = ['ma1', 'h3o', 'xyz', 'ma', 'ma5', 'le0']
    for p in test_validations:
        try:
            is_valid = validate_pinyin(p)
            print(f"{p:10s} -> valid={is_valid}")
        except Exception as e:
            print(f"{p:10s} -> ERROR: {e}")
    
    print("\n=== å¤šéŸ³å­—æ£€æŸ¥ ===")
    test_hanzis = ['ä¸­', 'é•¿', 'è¡Œ', 'å¥½', 'æˆ‘']
    for h in test_hanzis:
        try:
            is_poly = is_polyphonic_char(h)
            pinyins = get_possible_pinyins(h)
            print(f"{h} -> polyphonic={is_poly}, pinyins={pinyins}")
        except Exception as e:
            print(f"{h} -> ERROR: {e}")
    
    print("\n=== æ‹¼éŸ³åºåˆ—å¤„ç†æµ‹è¯• ===")
    test_seq = "ni3 hao3 jia1 hao4"
    try:
        split = split_pinyin_sequence(test_seq)
        print(f"æ‹†åˆ†: {test_seq} -> {split}")
        joined = join_pinyin_sequence(split)
        print(f"åˆå¹¶: {split} -> {joined}")
    except Exception as e:
        print(f"ERROR: {e}")
    
    print("\n=== ç»Ÿè®¡æµ‹è¯• ===")
    stats = PinyinStatistics()
    test_data = [
        ("ä½ å¥½", "ni3 hao3"),
        ("ä¸­å›½", "zhong1 guo2"),
        ("ä¸­å¿ƒ", "zhong1 xin1"),
        ("å¥½çš„", "hao3 de5"),
    ]
    try:
        stats.update_from_batch(test_data)
        stats.print_summary()
    except Exception as e:
        print(f"ERROR: {e}")
